{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import os\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill missing values with mean and median\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GKnn Algorithm\n",
    "def GKnn(impute_df):\n",
    "    for i in range(len(empty_loc_cols)-1):\n",
    "\n",
    "        \n",
    "        ## Differentiate numerical and categorical data\n",
    "        numerical_cols = impute_df._get_numeric_data().columns\n",
    "        cols = impute_df.columns\n",
    "        categorical_cols = list(set(cols) - set(numerical_cols))\n",
    "        num_df = impute_df.loc[:,numerical_cols]        #numerical dataframe\n",
    "        cat_df = impute_df.loc[:,categorical_cols]      #categorical dataframe\n",
    "        \n",
    "        \n",
    "        num_ck=num_df.iloc[empty_loc_cols[i],:]\n",
    "        num_cp=num_df.copy()\n",
    "        num_cp.drop([i + 1], axis = 0)             #### depends on indexing\n",
    "\n",
    "        cat_ck=cat_df.iloc[empty_loc_cols[i],:]\n",
    "        cat_cp=cat_df.copy()\n",
    "        cat_cp.drop([i + 1], axis = 0)             #### depends on indexing\n",
    "        \n",
    "        \n",
    "        # Compare queue and reference queue subtraction\n",
    "        t1=pd.DataFrame()\n",
    "        t2=pd.DataFrame(data = None, columns=cat_cp.columns, index=cat_cp.index)\n",
    "        \n",
    "        for j in range(num_cp.index.size):\n",
    "            temp=pd.Series(num_cp.iloc[j,:]-num_ck)\n",
    "            t1=t1.append(temp,ignore_index=True)\n",
    "            \n",
    "            if(cat_cp.iloc[j,:].equals(cat_ck)):\n",
    "                t2.iloc[j,:] = 1\n",
    "            else:\n",
    "                t2.iloc[j,:] = 0\n",
    "\n",
    "        t1.reset_index(drop=True, inplace=True)\n",
    "        t2.reset_index(drop=True, inplace=True)\n",
    "        t = pd.concat([t1, t2], axis=1)\n",
    "\n",
    "            \n",
    "        mmax=t.abs().max().max()\n",
    "        mmin=t.abs().min().min()\n",
    "        rho=0.5\n",
    "\n",
    "        #3, seeking correlation coefficient\n",
    "        ksi=((mmin+rho*mmax)/(abs(t)+rho*mmax))\n",
    "\n",
    "        #4, seeking relevance\n",
    "        r=ksi.sum(axis=1)/ksi.columns.size\n",
    "\n",
    "        #5, relevance ranking, get the result r3>r2>r1\n",
    "        result=r.sort_values(ascending=False)\n",
    "\n",
    "        #6 add result to NaN locations\n",
    "        index = result.iloc[[0]].index[0]\n",
    "        for k in range(len(empty_loc[0])-1):\n",
    "            if(empty_loc_cols[i] == empty_loc[0][k]):\n",
    "                impute_df.iloc[empty_loc[0][k], empty_loc[1][k]] = impute_df.iloc[index, empty_loc[1][k]]\n",
    "    return impute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute NRMS\n",
    "\n",
    "from sklearn import metrics\n",
    "#Frobenius Fun\n",
    "def frob(x):\n",
    "    return np.linalg.norm(x, 'fro')\n",
    "\n",
    "#NRMS\n",
    "def nrms(original, imputed):\n",
    "    x = frob(imputed - original) / frob(original)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import xlsx files as pandas dataframe\n",
    "path = '../Course Project Datasets/Incomplete Datasets Without Labels/Spam'\n",
    "complete_df = pd.read_excel('../Course Project Datasets/Original Datasets Without Labels/Spam.xlsx', header = None)\n",
    "incomplete_df_name_list = []\n",
    "incomplete_df_list = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        incomplete_df_list.append(pd.read_excel(path+\"/\"+filename, header=None))\n",
    "        incomplete_df_name_list.append(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imputed_df_list = []\n",
    "nrms_data = []\n",
    "index = 0\n",
    "for incomplete_df in incomplete_df_list:\n",
    "\n",
    "    incomplete_df.reset_index()\n",
    "    complete_df.reset_index()\n",
    "    \n",
    "    complete_df.columns=[\"F\"+str(i) for i in range(complete_df.shape[1])]\n",
    "    incomplete_df.columns=[\"F\"+str(i) for i in range(incomplete_df.shape[1])]\n",
    "    \n",
    "    ## find empty locations\n",
    "    empty_loc = np.where(pd.isnull(incomplete_df))\n",
    "    empty_loc_cols = np.unique(empty_loc[0])\n",
    "    \n",
    "    ## Replace NaN values to mean values\n",
    "    incomplete_df = DataFrameImputer().fit_transform(incomplete_df)\n",
    "    \n",
    "    ## GKnn\n",
    "    imputed_df = GKnn(incomplete_df)\n",
    "    \n",
    "    ##Compute NRMS\n",
    "    nrmser = nrms(complete_df, imputed_df)\n",
    "    nrms_data.append({incomplete_df_name_list[index]: nrmser})\n",
    "    \n",
    "    imputed_df_list.append(imputed_df)\n",
    "    index+=1\n",
    "nrms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save imputed dataframes to xlsx\n",
    "index = 0\n",
    "for df in imputed_df_list:\n",
    "    df.to_excel(\"./Imputed/Spam/\"+incomplete_df_name_list[index]+\".xlsx\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make Dictionary of dataset_name : nrms_values\n",
    "nrms_dict = {}\n",
    "index = 0;\n",
    "for imputed_df in imputed_df_list:\n",
    "    nrmser = nrms(complete_df, imputed_df)\n",
    "    nrms_dict.update( {incomplete_df_name_list[index]: nrmser} )\n",
    "    index+=1\n",
    "nrms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dictionary as csv file\n",
    "import csv\n",
    "with open('./NRMS_AE/Spam.csv', 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in nrms_dict.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
